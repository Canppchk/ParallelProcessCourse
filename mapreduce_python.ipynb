{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "สมาชิกผู้จัดทำ\n",
        "\n",
        "สิทธิเจตน์ วงศ์ทิชาวัฒน์ 6210503853\n",
        "\n",
        "นทวัจน์ เมี้ยนละม้าย 6210503624"
      ],
      "metadata": {
        "id": "yMNA53x97HGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt from\n",
        "\n",
        "https://colab.research.google.com/github/pnavaro/big-data/blob/master/notebooks/05-MapReduce.ipynb\n",
        "\n",
        "https://colab.research.google.com/github/RPI-DATA/course-intro-ml-app/blob/master/content/notebooks/18-big-data/01-intro-mapreduce.ipynb\n"
      ],
      "metadata": {
        "id": "EzG3Mnc_9jQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional programming review\n"
      ],
      "metadata": {
        "id": "bZnP_e2f9ujD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(2 * i)\n",
        "    return result"
      ],
      "metadata": {
        "id": "UkozhMOG9tgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code violates the \"do not repeat yourself\" principle of good software engineering practice.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\n"
      ],
      "metadata": {
        "id": "Rl6Bvewx-KAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vic2yGY-JaU",
        "outputId": "e2b1aa66-0f5a-4efe-8848-4d2c50a96b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the code"
      ],
      "metadata": {
        "id": "QIuW-ZQM-c2l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOCXducr70PY"
      },
      "outputs": [],
      "source": [
        "def double(x):\n",
        "    return x*2\n",
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(double(i))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj8S6VUwJhFj",
        "outputId": "3e208440-88a3-4412-862d-90fe5cb5da19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still \n",
        "\n",
        "The above code violates the \"do not repeat yourself\" principle of good software engineering practice.\n",
        "\n",
        "\n",
        "# Passing function as value\n",
        "Consider:\n",
        "\n"
      ],
      "metadata": {
        "id": "cCKw4soM_AWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_f_to_everything_in(f, data):\n",
        "    result = []\n",
        "    for x in data:\n",
        "        result.append(f(x))\n",
        "    return result"
      ],
      "metadata": {
        "id": "CwfyRyB6_GGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_f_to_everything_in(double, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_UTeGdI_PDj",
        "outputId": "2f3475e5-a55d-4c34-c097-b67298a80d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lambda expressions\n",
        "We can use anonymous functions to save having to define a function each time we want to use map.\n"
      ],
      "metadata": {
        "id": "4HiU3GK6_U-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apply_f_to_everything_in(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PDu7jOy_W2s",
        "outputId": "3164c213-237d-4cc5-8adb-851dba89dfec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider this code.\n",
        "def concat_everything_in(data1, data2):\n",
        "    result = []\n",
        "    for i,j in zip(data1,data2):\n",
        "        result.append( i+ j)\n",
        "    return result\n",
        "\n",
        " \n",
        "\n",
        "concat_everything_in (['a','c'],['b','d'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLcHJj5_IYDl",
        "outputId": "6cc5db2d-3de6-4d3c-fc1e-6a50bdc50080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ab', 'cd']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#solution\n",
        "def concat (d1,d2):\n",
        "  return d1+d2\n",
        "def apply_f_to_everything_2_arg(f, data1, data2):\n",
        "    result = []\n",
        "    for x,y in zip(data1,data2):\n",
        "        result.append(f(x,y))\n",
        "    return result\n",
        "apply_f_to_everything_2_arg(concat,['a','c'],['b','d'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0-QCd0jJwYb",
        "outputId": "cccf5c9b-8ffb-423f-b6bb-3be62e0b7d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ab', 'cd']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  what is wrong with this call: apply_f_to_everything_2_arg (concant_everything_in, .....)\n",
        "\n",
        "def concat_everything_in(data1, data2):\n",
        "    result = []\n",
        "    for i,j in zip(data1,data2):\n",
        "        result.append( i+ j)\n",
        "    return result\n",
        "\n",
        " \n",
        "apply_f_to_everything_2_arg(concat_everything_in,['a','c'],['b','d'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jiLhX99jqEZ",
        "outputId": "82d9a412-0453-43d2-8852-58db968bac55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ab'], ['cd']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python's `map` function\n",
        "\n",
        "- Python has a built-in function `map` which is much faster than our version."
      ],
      "metadata": {
        "id": "TxzoSnB2_e3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKXPS8O__f15",
        "outputId": "e9b61469-2436-4174-8d90-fc9f93b3ef8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f5aca3575d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing reduce\n",
        "\n",
        "- The `reduce` function is an example of a [fold](https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29).\n",
        "\n",
        "- There are different ways we can fold data.\n",
        "\n",
        "- The following implements a *left* fold."
      ],
      "metadata": {
        "id": "CH3sb_dx_nVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def foldl(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        print (z)\n",
        "        return z\n",
        "    else:\n",
        "        head = data[0]\n",
        "        tail = data[1:]\n",
        "        print (\"Folding\", head, \"with\", tail, \"using\", z)\n",
        "        partial_result = f(z, data[0])\n",
        "        print (\"Partial result is\", partial_result)\n",
        "        return foldl(f, tail, partial_result)  "
      ],
      "metadata": {
        "id": "lo9BHA83_o1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add(x, y):\n",
        "    return x + y\n",
        "\n",
        "foldl(add, [3, 3, 3, 3, 3], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CwCYj-7ADn6",
        "outputId": "573b1c8e-18b8-4253-ed10-629b3503652e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 3 with [3, 3, 3, 3] using 0\n",
            "Partial result is 3\n",
            "Folding 3 with [3, 3, 3] using 3\n",
            "Partial result is 6\n",
            "Folding 3 with [3, 3] using 6\n",
            "Partial result is 9\n",
            "Folding 3 with [3] using 9\n",
            "Partial result is 12\n",
            "Folding 3 with [] using 12\n",
            "Partial result is 15\n",
            "15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mul(x, y):\n",
        "    return x * y\n"
      ],
      "metadata": {
        "id": "V5XuxyYmAbao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the result?\n",
        "foldl(mul, [3, 3, 3, 3, 3], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgvA1pW-Ahm1",
        "outputId": "59c1ed38-a6c4-4c56-84b5-ff0a4fb26616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 3 with [3, 3, 3, 3] using 0\n",
            "Partial result is 0\n",
            "Folding 3 with [3, 3, 3] using 0\n",
            "Partial result is 0\n",
            "Folding 3 with [3, 3] using 0\n",
            "Partial result is 0\n",
            "Folding 3 with [3] using 0\n",
            "Partial result is 0\n",
            "Folding 3 with [] using 0\n",
            "Partial result is 0\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to modify it to get 3^5\n",
        "foldl(mul, [3, 3, 3, 3, 3], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKVZcbS9Aseq",
        "outputId": "17ebfa9c-deeb-4110-f31e-eeb87babfabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 3 with [3, 3, 3, 3] using 1\n",
            "Partial result is 3\n",
            "Folding 3 with [3, 3, 3] using 3\n",
            "Partial result is 9\n",
            "Folding 3 with [3, 3] using 9\n",
            "Partial result is 27\n",
            "Folding 3 with [3] using 27\n",
            "Partial result is 81\n",
            "Folding 3 with [] using 81\n",
            "Partial result is 243\n",
            "243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foldl(lambda x, y: x + y, [1, 2, 3, 4, 5], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSyHMIJ7AWGB",
        "outputId": "af2735da-2ad6-4d48-9160-c94d97fd5795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is 1\n",
            "Folding 2 with [3, 4, 5] using 1\n",
            "Partial result is 3\n",
            "Folding 3 with [4, 5] using 3\n",
            "Partial result is 6\n",
            "Folding 4 with [5] using 6\n",
            "Partial result is 10\n",
            "Folding 5 with [] using 10\n",
            "Partial result is 15\n",
            "15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOvcDX5cA6co",
        "outputId": "441319a6-11cf-4368-9ec5-1330f63b1f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is -1\n",
            "Folding 2 with [3, 4, 5] using -1\n",
            "Partial result is -3\n",
            "Folding 3 with [4, 5] using -3\n",
            "Partial result is -6\n",
            "Folding 4 with [5] using -6\n",
            "Partial result is -10\n",
            "Folding 5 with [] using -10\n",
            "Partial result is -15\n",
            "-15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: what is the equivalent expression\n",
        "\n",
        "(((((0 - 1) - 2) - 3) - 4) - 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNPCml7QBeev",
        "outputId": "be7593c6-cc6d-4d76-9bd5-685a29bc53b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question: or is it the same as above?\n",
        "(5- (4 - (3- (2- (1 -  0)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rux0Q28xCGWi",
        "outputId": "6769c9da-bdbb-4acd-f359-800cfe82ab5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def foldr(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        return z\n",
        "    else:\n",
        "        return f(data[0], foldr(f, data[1:], z))    "
      ],
      "metadata": {
        "id": "preaVhTnCwA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foldr(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWOpiHfACz-P",
        "outputId": "ccff1106-af71-4140-e148-36f037e93bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foldr(lambda x, y: x + y, [1, 2, 3, 4, 5], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhgTyFDrEqyW",
        "outputId": "ff2b97f2-0b15-44a4-f329-05c878141c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why foldl and foldr give different result for subtract.\n",
        "\n",
        "- Subtraction is neither [commutative](https://en.wikipedia.org/wiki/Commutative_property) nor [associative](https://en.wikipedia.org/wiki/Associative_property), so the order in which apply the fold matters:"
      ],
      "metadata": {
        "id": "bi_YtIKNEgFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python's reduce function.\n",
        "Python's built-in reduce function is a left fold."
      ],
      "metadata": {
        "id": "LLE8vibKB31r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "reduce(lambda x, y: x + y, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxtR1-m8B3Ml",
        "outputId": "dfd8a26f-451f-4872-cc6f-99fb6231a167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6EOgi8LB_y5",
        "outputId": "adce9a2f-f41a-4415-a920-55557c87432e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functional programming and parallelism\n",
        "Functional programming lends itself to parallel programming.\n",
        "\n",
        "The map function can easily be parallelised through data-level parallelism,\n",
        "\n",
        "provided that the function we supply as an argument is free from side-effects\n",
        "(which is why we avoid working with mutable data).\n",
        "We can see this by rewriting it so:"
      ],
      "metadata": {
        "id": "k0bfmEv3DaFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_computation(f, result, data, i):\n",
        "    print (\"Computing the \", i, \"th result...\")\n",
        "    # This could be scheduled on a different CPU\n",
        "    result[i] = f(data[i])\n",
        "\n",
        "def my_map(f, data):\n",
        "    result = [None] * len(data)\n",
        "    for i in range(len(data)):\n",
        "        perform_computation(f, result, data, i)\n",
        "    # Wait for other CPUs to finish, and then..\n",
        "    return result"
      ],
      "metadata": {
        "id": "COjXfU54Db5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_map(lambda x: x * x, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbfViLtyDteq",
        "outputId": "b6c05358-ec78-46d6-9217-441bdae45a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the  0 th result...\n",
            "Computing the  1 th result...\n",
            "Computing the  2 th result...\n",
            "Computing the  3 th result...\n",
            "Computing the  4 th result...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multithread map"
      ],
      "metadata": {
        "id": "d3kFu-ZXD1DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def schedule_computation_threaded(f, result, data, threads, i):    \n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job(): \n",
        "        print (\"Processing data:\", data[i], \"... \")\n",
        "        result[i] = f(data[i])\n",
        "        print (\"Finished job #\", i)    \n",
        "        print (\"Result was\", result[i])       \n",
        "    threads[i] = Thread(target=my_job)\n",
        "    \n",
        "def my_map_multithreaded(f, data):\n",
        "    n = len(data)\n",
        "    result = [None] * n\n",
        "    threads = [None] * n\n",
        "    print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded(f, result, data, threads, i)\n",
        "    print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    print (\"All done.\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "aGfTFTuRD3DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_map_multithreaded(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhqR_JRqD9CR",
        "outputId": "b35c99ed-dd07-438e-f07d-61e37d34f2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Processing data: 1 ... \n",
            "Finished job # 0\n",
            "Result was 1\n",
            "Processing data: 2 ... \n",
            "Finished job # 1\n",
            "Result was 4\n",
            "Processing data:Processing data:  3 ... \n",
            "Finished job # 2\n",
            "Result was 9\n",
            "4 ... \n",
            "Finished job # 3\n",
            "Result was 16\n",
            "Processing data:Waiting for jobs to finish.. \n",
            " 5 ... \n",
            "Finished job # 4\n",
            "Result was 25\n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import uniform\n",
        "from time import sleep\n",
        "\n",
        "def a_function_which_takes_a_long_time(x):\n",
        "    sleep(uniform(2, 10))  # Simulate some long computation\n",
        "    return x*x\n",
        "\n",
        "my_map_multithreaded(a_function_which_takes_a_long_time, [1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km4u3oloEA9y",
        "outputId": "24f81bcf-4cc6-48d0-8dd4-c28f4d316f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Processing data: 1 ... \n",
            "Processing data: 2 ... \n",
            "Processing data: Processing data: 3 4 ... \n",
            "... \n",
            "Processing data:Waiting for jobs to finish.. \n",
            " 5 ... \n",
            "Finished job # 1\n",
            "Result was 4\n",
            "Finished job # 4\n",
            "Result was 25\n",
            "Finished job # 3\n",
            "Result was 16\n",
            "Finished job # 2\n",
            "Result was 9\n",
            "Finished job # 0\n",
            "Result was 1\n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map Reduce\n",
        "\n",
        "- Map Reduce is a _programming model_ for scalable parallel processing.\n",
        "- Scalable here means that it can work on big data with very large compute clusters.\n",
        "- There are many implementations: e.g. Apache Hadoop and Apache Spark.\n",
        "- We can use Map-Reduce with any programming language:\n",
        "    - Hadoop is written in Java\n",
        "    - Spark is written in Scala, but has a Python interface.\n",
        "- *Functional programming* languages such as Python or Scala fit very well with the Map Reduce model:\n",
        "    - However, we don't *have* to use functional programming."
      ],
      "metadata": {
        "id": "4Ac4-c3vEKGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typical steps in a Map Reduce Computation\n",
        "\n",
        "1. ETL a big data set.\n",
        "2. _Map_ operation: extract something you care about from each row\n",
        "3. \"Shuffle and Sort\": task/node allocation\n",
        "4. _Reduce_ operation: aggregate, summarise, filter or transform\n",
        "5. Write the results."
      ],
      "metadata": {
        "id": "I2hrVno0EK7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks for Map Reduce\n",
        "\n",
        "- The data set, and the state of each stage of the computation, is represented as a set of key-value pairs.\n",
        "\n",
        "- The programmer provides a map function:\n",
        "\n",
        "$\\operatorname{map}(k, v) \\rightarrow \\; \\left< k', v' \\right>*$  \n",
        "\n",
        "- and a reduce function:\n",
        "\n",
        "$\\operatorname{reduce}(k', \\left< k', v'\\right> *) \\rightarrow \\; \\left< k', v''\n",
        "\\right> *$\n",
        "\n",
        "- The $*$ refers to a *collection* of values.\n",
        "\n",
        "- These collections are *not* ordered.\n",
        "\n",
        "\n",
        "## Word Count Example\n",
        "\n",
        "- In this simple example, the input is a set of URLs, each record is a document.\n",
        "\n",
        "- Problem: compute how many times each word has occurred across data set.\n",
        "\n",
        "\n",
        "## Word Count: Map \n",
        "\n",
        "\n",
        "- The input to $\\operatorname{map}$ is a mapping:\n",
        "\n",
        "- Key: URL\n",
        "- Value: Contents of document\n",
        "\n",
        "\n",
        "$\\left< document1, to \\; be \\; or \\; not \\; to \\; be \\right>$  \n",
        "    \n",
        "\n",
        "- In this example, our $\\operatorname{map}$ function will process a given URL, and produces a mapping:\n",
        "\n",
        "- Key: word\n",
        "- Value: 1\n",
        "\n",
        "- So our original data-set will be transformed to:\n",
        "  \n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$\n",
        "  $\\left< or, 1 \\right>$\n",
        "  $\\left< not, 1 \\right>$\n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$\n",
        "\n",
        "\n",
        "  ## Word Count: Reduce\n",
        "\n",
        "\n",
        "- The reduce operation groups values according to their key, and then performs areduce on each key.\n",
        "\n",
        "- The collections are partitioned across different storage units, therefore.\n",
        "\n",
        "- Map-Reduce will fold the data in such a way that it minimises data-copying across the cluster.\n",
        "\n",
        "- Data in different partitions are reduced separately in parallel.\n",
        "\n",
        "- The final result is a reduce of the reduced data in each partition.\n",
        "\n",
        "- Therefore it is very important that our operator *is both commutative and associative*.\n",
        "\n",
        "- In our case the function is the `+` operator\n",
        "\n",
        "  $\\left< be, 2 \\right>$  \n",
        "  $\\left< not, 1 \\right>$  \n",
        "  $\\left< or, 1 \\right>$  \n",
        "  $\\left< to, 2 \\right>$  \n",
        "\n",
        "\n",
        "## Map and Reduce compared with Python\n",
        "\n",
        "- Notice that these functions are formulated differently from the standard Python functions of the same name.\n",
        "\n",
        "- The `reduce` function works with key-value *pairs*.\n",
        "\n",
        "- It would be more apt to call it something like `reduceByKey`.\n",
        "\n",
        "\n",
        "## MiniMapReduce\n",
        "\n",
        "- To illustrate how the Map-Reduce programming model works, we can implement our own Map-Reduce framework in Python.\n",
        "\n",
        "- This *illustrates* how a problem can be written in terms of `map` and `reduce` operations.\n",
        "\n",
        "- Note that these are illustrative functions; this is *not* how Hadoop or Apache Spark actually implement them.\n"
      ],
      "metadata": {
        "id": "ExPpXihuERI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "#\n",
        "#   MiniMapReduce\n",
        "#\n",
        "# A non-parallel, non-scalable Map-Reduce implementation\n",
        "##########################################################\n",
        "\n",
        "def groupByKey(data):\n",
        "    result = dict()\n",
        "    for key, value in data:\n",
        "        if key in result:\n",
        "            result[key].append(value)\n",
        "        else:\n",
        "            result[key] = [value]\n",
        "    return result\n",
        "        \n",
        "def reduceByKey(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return map(lambda key: \n",
        "                   (key, reduce(f, key_values[key])), \n",
        "                       key_values)"
      ],
      "metadata": {
        "id": "NLTnoJmmFHl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = map(lambda x: (x, 1), \"to be or not to be\".split())\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n-JsQjJEuO4",
        "outputId": "7e2ab3ff-4551-494e-b0d3-1ddf34bf866f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f5aca3fa790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groupByKey(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzN763j1FYz9",
        "outputId": "dec46082-3b93-4ac8-fdb8-3311cd86072d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'be': [1, 1], 'not': [1], 'or': [1], 'to': [1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduceByKey(lambda x, y: x + y, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-eNOpAiFjGE",
        "outputId": "25b4f0f2-d47e-4147-b76d-9a7505f3a0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f5aca363c50>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallelising MiniMapReduce\n",
        "\n",
        "- We can easily turn our Map-Reduce implementation into a parallel, multi-threaded framework\n",
        "by using the `my_map_multithreaded` function we defined earlier.\n",
        "\n",
        "- This will allow us to perform map-reduce computations that exploit parallel processing using *multiple* cores on a *single* computer."
      ],
      "metadata": {
        "id": "tDM3DQ5PFtmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduceByKey_multithreaded(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return my_map_multithreaded(\n",
        "        lambda key: (key, reduce(f, key_values[key])), key_values.keys())"
      ],
      "metadata": {
        "id": "dngxnDjzFo79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduceByKey_multithreaded(lambda x, y: x + y, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrEzMhI_F2y-",
        "outputId": "1cec2bec-9268-4383-f320-1f96068d01ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Waiting for jobs to finish.. \n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallelising the reduce step\n",
        "\n",
        "- Provided that our operator is both associative and commutative we can\n",
        "also parallelise the reduce operation.\n",
        "\n",
        "- We partition the data into approximately equal subsets.\n",
        "\n",
        "- We then reduce each subset independently on a separate core.\n",
        "\n",
        "- The results can be combined in a final reduce step."
      ],
      "metadata": {
        "id": "JckvivXjGEh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partition data"
      ],
      "metadata": {
        "id": "H6BQzCC9GMNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, split_points):\n",
        "    partitions = []\n",
        "    n = 0\n",
        "    for i in split_points:\n",
        "        partitions.append(data[n:i])\n",
        "        n = i\n",
        "    partitions.append(data[n:])\n",
        "    return partitions\n",
        "\n",
        "data = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
        "partitioned_data = split_data(data, [3])\n",
        "partitioned_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N71VL2BKGGOO",
        "outputId": "86b5067c-e119-4776-abf7-7365d54482c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 'b', 'c'], ['d', 'e', 'f', 'g']]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def parallel_reduce(f, partitions):\n",
        "\n",
        "    n = len(partitions)\n",
        "    results = [None] * n\n",
        "    threads = [None] * n\n",
        "    \n",
        "    def job(i):\n",
        "        results[i] = reduce(f, partitions[i])\n",
        "\n",
        "    for i in range(n):\n",
        "        threads[i] = Thread(target = lambda: job(i))\n",
        "        threads[i].start()\n",
        "    \n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    \n",
        "    return reduce(f, results)\n",
        "\n",
        "parallel_reduce(lambda x, y: x + y, partitioned_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "plwyYbd8GVN_",
        "outputId": "ffec44a6-ff3b-4fa7-8e6e-49116d0a2d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefg'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework\n",
        "\n",
        "\n",
        "First generate text file"
      ],
      "metadata": {
        "id": "rqjBgXBLLxak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lorem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWYzfy_0PsKn",
        "outputId": "4b8b758c-9c69-425b-a111-828f11e81d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lorem in /usr/local/lib/python3.7/dist-packages (0.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lorem import text\n",
        "num = 10000\n",
        "for i in range(4):\n",
        "    with open(\"sample{0:02d}.txt\".format(i), \"w\") as f:\n",
        "        for j in range(num):\n",
        "          f.write(text()+'\\n')"
      ],
      "metadata": {
        "id": "XqwGPt-yPmmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "MmILUrSioX5J",
        "outputId": "5bbe6690-e31d-4ffb-c858-dc5f6bb596db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sit quiquia velit sit dolorem dolore ut ut. Sit quisquam velit sit dolore magnam numquam. Ut est dolorem dolor dolor dolor. Eius ipsum aliquam aliquam quaerat ut dolorem. Porro quaerat tempora ut adipisci etincidunt non.\\n\\nNon amet consectetur sed porro dolor. Aliquam voluptatem est etincidunt consectetur dolor dolor non. Dolore etincidunt dolorem neque. Adipisci sit amet magnam. Labore porro neque est modi porro. Consectetur dolore dolorem sit. Eius quisquam dolorem velit neque. Voluptatem quiquia aliquam dolore ipsum.\\n\\nSit sed aliquam dolorem amet sit adipisci. Labore porro ipsum modi est voluptatem tempora voluptatem. Consectetur quisquam labore dolorem modi quisquam est. Quisquam labore modi velit sed quiquia magnam consectetur. Voluptatem quiquia adipisci porro numquam. Sed porro dolore quiquia non voluptatem ut. Dolor magnam labore dolorem amet ut. Non porro etincidunt dolorem amet tempora. Velit dolorem adipisci dolorem dolor etincidunt eius.\\n\\nUt adipisci consectetur non quisquam est etincidunt. Porro quisquam quiquia velit voluptatem porro. Est aliquam dolor adipisci aliquam. Non neque quiquia voluptatem modi. Sit est consectetur sit voluptatem eius. Neque sit adipisci tempora consectetur etincidunt est. Adipisci est quaerat eius porro sit sed adipisci. Porro tempora dolor neque quiquia. Sed ipsum modi etincidunt est. Quiquia quiquia neque dolor.'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "files = sorted(glob.glob('sample0*.txt'))\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egVTDckkP2fQ",
        "outputId": "aa3145c8-29a9-4ff1-d2bc-050d108316c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample00.txt', 'sample01.txt', 'sample02.txt', 'sample03.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seVa8kgOQBdl",
        "outputId": "9a83ea55-0154-42ed-fe31-9c5f11d6c38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 55644\n",
            "-rw-r--r-- 1 root root 14139478 Jan 30 16:33 sample00.txt\n",
            "-rw-r--r-- 1 root root 14271255 Jan 30 16:33 sample01.txt\n",
            "-rw-r--r-- 1 root root 14299183 Jan 30 16:33 sample02.txt\n",
            "-rw-r--r-- 1 root root 14252029 Jan 30 16:33 sample03.txt\n",
            "drwxr-xr-x 1 root root     4096 Jan  7 14:33 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: write iterative version to perform the wordcount over the above files"
      ],
      "metadata": {
        "id": "cbyUuKpeP_FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "Wtp585p_WRcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1) iterative code\n",
        "\n",
        "data0 = open(\"sample00.txt\", \"r\").read()\n",
        "data1 = open(\"sample01.txt\", \"r\").read()\n",
        "data2 = open(\"sample02.txt\", \"r\").read()\n",
        "data3 = open(\"sample03.txt\", \"r\").read()\n",
        "\n",
        "raw_text = data0 + data1 + data2 + data3\n",
        "\n",
        "for char in '-.,\\n':\n",
        "    raw_text = raw_text.replace(char,' ')\n",
        "low_text = raw_text.lower()\n",
        "wordcount={}\n",
        "\n",
        "start = time.time()\n",
        "for word in sorted(low_text.split()):\n",
        "    if word not in wordcount:\n",
        "        wordcount[word] = 1\n",
        "    else:\n",
        "        wordcount[word] += 1\n",
        "\n",
        "end = time.time()\n",
        "print(len(wordcount)) \n",
        "print(wordcount)\n",
        "print('Time taken in seconds :', end - start) "
      ],
      "metadata": {
        "id": "v2dYW7bpRDVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80970724-83c4-4bb2-943d-a88ad309625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "{'adipisci': 299631, 'aliquam': 299743, 'amet': 300276, 'consectetur': 300609, 'dolor': 300055, 'dolore': 299975, 'dolorem': 300635, 'eius': 300203, 'est': 300067, 'etincidunt': 299611, 'ipsum': 299932, 'labore': 299859, 'magnam': 298880, 'modi': 300175, 'neque': 299587, 'non': 299753, 'numquam': 300077, 'porro': 299082, 'quaerat': 299739, 'quiquia': 299799, 'quisquam': 300085, 'sed': 300029, 'sit': 299122, 'tempora': 299861, 'ut': 298310, 'velit': 299549, 'voluptatem': 299896}\n",
            "Time taken in seconds : 6.700387477874756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Map Reduce version to perform wordcount"
      ],
      "metadata": {
        "id": "pXVZw62TRJrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2) map reduce python\n",
        "\n",
        "#create function to return the results in the form  ('word1',1)\n",
        "words = low_text.split()\n",
        "def tup(data):\n",
        "  return (data, 1)\n",
        "\n",
        "start = time.time() \n",
        "#call python map function to return [('word1',1),('word1',1), ('word2',1),... ]\n",
        "#by looping for all above files\n",
        "\n",
        "map_data = map(tup, words)\n",
        "map_data\n",
        "\n",
        "# take the results from the above map\n",
        "# and write reduce to return [('word1',2),('word1',1) ....]\n",
        "wordcount = reduceByKey(lambda x,y: x+y , sorted(map_data))\n",
        "end = time.time() \n",
        "wordcount = list(wordcount)\n",
        "print(len(wordcount))\n",
        "print(wordcount)\n",
        "\n",
        "print('Time taken in seconds :', end - start) "
      ],
      "metadata": {
        "id": "zsCbgdTCRNkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acd5bf1-47f5-439f-8ce3-fa6030873f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "[('adipisci', 299631), ('aliquam', 299743), ('amet', 300276), ('consectetur', 300609), ('dolor', 300055), ('dolore', 299975), ('dolorem', 300635), ('eius', 300203), ('est', 300067), ('etincidunt', 299611), ('ipsum', 299932), ('labore', 299859), ('magnam', 298880), ('modi', 300175), ('neque', 299587), ('non', 299753), ('numquam', 300077), ('porro', 299082), ('quaerat', 299739), ('quiquia', 299799), ('quisquam', 300085), ('sed', 300029), ('sit', 299122), ('tempora', 299861), ('ut', 298310), ('velit', 299549), ('voluptatem', 299896)]\n",
            "Time taken in seconds : 10.319125890731812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write multithread map reduce"
      ],
      "metadata": {
        "id": "eY3-CmKvRddI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) multithread map and reduce\n",
        "# with  partition sizes:\n",
        "# 3.1) one line per partition\n",
        "# 3.2) four line per partition\n",
        "# 3.3) one file per partition\n",
        "\n",
        "raw_text = data0 + data1 + data2 + data3\n",
        "\n",
        "for char in '-.,':\n",
        "      raw_text = raw_text.replace(char,' ').lower()\n",
        "\n",
        "raw_lines = [s for s in raw_text.splitlines() if s]\n",
        "print(len(raw_lines))\n",
        "\n",
        "def tup(data):\n",
        "  return (data, 1)\n",
        "\n",
        "# MAPPING\n",
        "def schedule_computation_threaded_map(f, result, data, threads, i):\n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job():\n",
        "        # print (\"Processing data:\", data[i], \"... \")\n",
        "        words = data[i].split()\n",
        "        result[i] = list(map(f, words))\n",
        "        # print (\"Finished job #\", i)    \n",
        "        # print (\"Result was\", result[i])       \n",
        "    threads[i] = Thread(target=my_job)\n",
        "\n",
        "def my_map_multithreaded_map(f, data):\n",
        "    n = len(data)\n",
        "    result = [None] * n\n",
        "    threads = [None] * n\n",
        "    # print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded_map(f, result, data, threads, i)\n",
        "    # print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    # print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    # print (\"All done.\")\n",
        "    return result\n",
        "\n",
        "# REDUCING\n",
        "def schedule_computation_threaded_reduce(f, result, data, threads, i):    \n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job(): \n",
        "        # print (\"Processing data:\", data[i], \"... \")\n",
        "        key_list = list(data[i].keys())\n",
        "        for key in range(len(key_list)):\n",
        "          result.append(f(i, key_list[key]))\n",
        "        # print (\"Finished job #\", i)\n",
        "        # print (\"Result was\", result)\n",
        "    threads[i] = Thread(target=my_job)\n",
        "\n",
        "def my_map_multithreaded_reduce(f, data):\n",
        "    n = len(data)\n",
        "    result = []\n",
        "    threads = [None] * n\n",
        "    # print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded_reduce(f, result, data, threads, i)\n",
        "    # print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    # print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    # print (\"All done.\")\n",
        "    return result\n",
        "\n",
        "def reduceByKey_multithreaded_line(f, data):\n",
        "    keys_values_in_line = []\n",
        "    for line in data:\n",
        "        keys_values_in_line.append(groupByKey(line))\n",
        "    return my_map_multithreaded_reduce(lambda i,key: (key, reduce(f, keys_values_in_line[i][key])), keys_values_in_line)\n",
        "\n",
        "# using my_map multithread\n",
        "\n",
        "# using multithread reduce"
      ],
      "metadata": {
        "id": "8IS2YwsSUDUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8a3560-9354-4d8f-d155-abcc2b58e6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# remove empty string from splited lines list\n",
        "\n",
        "start1 = time.time() \n",
        "lines_tuple1 = my_map_multithreaded_map(tup, raw_lines)\n",
        "lines_reduce_tuple1 = reduceByKey_multithreaded_line(lambda x, y: x + y, lines_tuple1)\n",
        "sorted_tuple1 = sorted(lines_reduce_tuple1, key=lambda x: x[0])\n",
        "wordcount1 = reduceByKey(lambda x,y: x + y, sorted_tuple1)\n",
        "wordcount1 = list(wordcount1)\n",
        "end1 = time.time() \n",
        "\n",
        "print(len(wordcount1))\n",
        "print(wordcount1)\n",
        "print('Time taken in seconds :', end1 - start1) \n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjs2SyxW1Du7",
        "outputId": "0e35179f-62ac-40d6-c01f-f7618e4b9c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "[('adipisci', 299631), ('aliquam', 299743), ('amet', 300276), ('consectetur', 300609), ('dolor', 300055), ('dolore', 299975), ('dolorem', 300635), ('eius', 300203), ('est', 300067), ('etincidunt', 299611), ('ipsum', 299932), ('labore', 299859), ('magnam', 298880), ('modi', 300175), ('neque', 299587), ('non', 299753), ('numquam', 300077), ('porro', 299082), ('quaerat', 299739), ('quiquia', 299799), ('quisquam', 300085), ('sed', 300029), ('sit', 299122), ('tempora', 299861), ('ut', 298310), ('velit', 299549), ('voluptatem', 299896)]\n",
            "Time taken in seconds : 57.40858030319214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "raw_lines2 = []\n",
        "\n",
        "mod = len(raw_lines) % 4\n",
        "\n",
        "k = ''\n",
        "for i in range(len(raw_lines)):\n",
        "  k = k + raw_lines[i]\n",
        "  if not ((i+1) % 4):\n",
        "    raw_lines2.append(k)\n",
        "    k = ''\n",
        "  if not (len(raw_lines) - i - 1):\n",
        "    raw_lines2.append(k)\n",
        "    k = ''\n",
        "\n",
        "print(len(raw_lines2))\n",
        "\n",
        "start2 = time.time() \n",
        "lines_tuple2 = my_map_multithreaded_map(tup, raw_lines2)\n",
        "lines_reduce_tuple2 = reduceByKey_multithreaded_line(lambda x, y: x + y, lines_tuple2)\n",
        "sorted_tuple2 = sorted(lines_reduce_tuple2, key=lambda x: x[0])\n",
        "wordcount2 = reduceByKey(lambda x,y: x + y, sorted_tuple2)\n",
        "wordcount2 = list(wordcount2)\n",
        "end2 = time.time() \n",
        "\n",
        "print(len(wordcount2))\n",
        "print(wordcount2)\n",
        "print('Time taken in seconds :', end2 - start2) \n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi4DDPSe08lp",
        "outputId": "5fae7696-d688-4f51-f3dc-430e440f9781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45003\n",
            "27\n",
            "[('adipisci', 299631), ('aliquam', 299743), ('amet', 300276), ('consectetur', 300609), ('dolor', 300055), ('dolore', 299975), ('dolorem', 300635), ('eius', 300203), ('est', 300067), ('etincidunt', 299611), ('ipsum', 299932), ('labore', 299859), ('magnam', 298880), ('modi', 300175), ('neque', 299587), ('non', 299753), ('numquam', 300077), ('porro', 299082), ('quaerat', 299739), ('quiquia', 299799), ('quisquam', 300085), ('sed', 300029), ('sit', 299122), ('tempora', 299861), ('ut', 298310), ('velit', 299549), ('voluptatem', 299896)]\n",
            "Time taken in seconds : 30.906075954437256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "raw_lines3 = []\n",
        "for char in '-.,':\n",
        "      data0 = data0.replace(char,' ').lower()\n",
        "      data1 = data1.replace(char,' ').lower()\n",
        "      data2 = data2.replace(char,' ').lower()\n",
        "      data3 = data3.replace(char,' ').lower()\n",
        "\n",
        "raw_lines3.append(data0)\n",
        "raw_lines3.append(data1)\n",
        "raw_lines3.append(data2)\n",
        "raw_lines3.append(data3)\n",
        "print(len(raw_lines3))\n",
        "\n",
        "start3 = time.time() \n",
        "lines_tuple3 = my_map_multithreaded_map(tup, raw_lines3)\n",
        "lines_reduce_tuple3 = reduceByKey_multithreaded_line(lambda x, y: x + y, lines_tuple3)\n",
        "sorted_tuple3 = sorted(lines_reduce_tuple3, key=lambda x: x[0])\n",
        "wordcount3 = reduceByKey(lambda x,y: x + y, sorted_tuple3)\n",
        "wordcount3 = list(wordcount3)\n",
        "end3 = time.time() \n",
        "\n",
        "print(len(wordcount3))\n",
        "print(wordcount3)\n",
        "print('Time taken in seconds :', end3 - start3) \n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PhA-uS32nTQ",
        "outputId": "09c06fab-5516-4cec-8cbc-f8f935eacdee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "27\n",
            "[('adipisci', 299631), ('aliquam', 299743), ('amet', 300276), ('consectetur', 300609), ('dolor', 300055), ('dolore', 299975), ('dolorem', 300635), ('eius', 300203), ('est', 300067), ('etincidunt', 299611), ('ipsum', 299932), ('labore', 299859), ('magnam', 298880), ('modi', 300175), ('neque', 299587), ('non', 299753), ('numquam', 300077), ('porro', 299082), ('quaerat', 299739), ('quiquia', 299799), ('quisquam', 300085), ('sed', 300029), ('sit', 299122), ('tempora', 299861), ('ut', 298310), ('velit', 299549), ('voluptatem', 299896)]\n",
            "Time taken in seconds : 5.0938401222229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report the time\n",
        "for 1),2),3) (3.1,3.2,3.3)\n",
        "\n",
        "Which one is the fastest?\n",
        "\n"
      ],
      "metadata": {
        "id": "4q0XHtoBVeIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iterative code : 6.700387477874756 (s)\n",
        "\n",
        "map reduce python : 10.319125890731812 (s)\n",
        "\n",
        "3) multithread map and reduce\n",
        "\n",
        "with  partition sizes:\n",
        "\n",
        "3.1) one line per partition : 57.40858030319214 (s)\n",
        "\n",
        "3.2) four line per partition : 30.906075954437256 (s)\n",
        "\n",
        "3.3) one file per partition : 5.0938401222229 (s)\n",
        "\n",
        "3.3 is fastest เพราะทำ multithread เพียงแค่ 4 ตัว และ overhead น้อยมาก\n"
      ],
      "metadata": {
        "id": "9XQMofmH6K4f"
      }
    }
  ]
}