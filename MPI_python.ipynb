{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obddpxn2k_RA"
      },
      "source": [
        "# สมาชิกผู้จัดทำ\n",
        "\n",
        "สิทธิเจตน์ วงศ์ทิชาวัฒน์ 6210503853\n",
        "\n",
        "นทวัจน์ เมี้ยนละม้าย 6210503624"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YGNAJau_uPU",
        "outputId": "2792fefc-87fa-469f-d8df-e0b4017b9067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "uSa9fHoEsKTV",
        "outputId": "ad1558f4-10af-4306-f0aa-0d025d883897"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-5be59830d07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m        \u001b[0;31m# iterate through rows of Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m            \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "# Program to multiply two matrices using nested loops\n",
        "\n",
        "t1 = time.time()\n",
        "# 3x3 matrix\n",
        "X = np.random.rand(100,100)\n",
        "# 3x4 matrix\n",
        "Y = np.random.rand(100,100)\n",
        "# result is 3x4\n",
        "result = np.zeros((100,100))\n",
        "\n",
        "# iterate through rows of X\n",
        "for i in range(len(X)):\n",
        "   # iterate through columns of Y\n",
        "   for j in range(len(Y[0])):\n",
        "       # iterate through rows of Y\n",
        "       for k in range(len(Y)):\n",
        "           result[i][j] += X[i][k] * Y[k][j]\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "# for r in result:\n",
        "#    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJjRUOhfe4Gu"
      },
      "source": [
        "# FILE : mpi-mul.py\n",
        "\n",
        "ตัวแปร\n",
        "\n",
        "**Line 11 :** workers คือ slave processes = comm.Get_size() - 1\n",
        "\n",
        "**Line 14 :** N คือขนาดของ array NxN numpy array\n",
        "\n",
        "**Line 17 :** mtrx_A คือ first numpy array value between 0 - 9 size NxN\n",
        "\n",
        "**Line 18 :** mtrx_B คือ second numpy array value between 0 - 9 size NxN\n",
        "\n",
        "**Line 19 :** mtrx_C คือ result numpy array\n",
        "\n",
        "**Line 22 :** mul_matrix function คือ matrix multiplier function ทำ *Z[i][j] += X[i][k] x Y[k][j]* ในทุก slave process\n",
        "\n",
        "**Line 30 :** distribute_data function คือแยก data ของ matrix จาก master process เป็นจำนวนเท่า workers และยัดเข้าไปใน slave process แต่ละตัว โดยใช้ comm.send()\n",
        "\n",
        "**Line 54 :** assemble_data function คือรวม data ของ matrix ที่ผ่านการคูณมาแล้วใน slave processes มาใส่ใน mtrx_C โดยใช้ comm.recv ใน master process\n",
        "\n",
        "จากผลที่ได้เวลาจาก 4, 8, 16 process จะน้อยลงตามลำดับแต่ก็ยังนานกว่า แบบ sequential อยู่ดี คิดว่าน่าจะมาจากการทำ matrix multiplication ต้องมีการสื่อสารมากทำให้ overhead เยอะมาก"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g1PUewLF_Zu9",
        "outputId": "a47226f2-fc10-4f9a-f5a6-be96178ffa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mpi-mul.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi-mul.py\n",
        "from mpi4py import MPI\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "# comm.Get_size() = master_process + slave_processes\n",
        "# workers = slave_processes\n",
        "workers = comm.Get_size() - 1\n",
        "\n",
        "# array of size 100x100, 1000x1000,5000x5000\n",
        "N = 1000 # N = 100, 1000, 5000\n",
        "\n",
        "# Generate numpy array NxN\n",
        "mtrx_A = np.random.randint(10,size=(N,N))\n",
        "mtrx_B = np.random.randint(10,size=(N,N))\n",
        "mtrx_C = []\n",
        "\n",
        "\n",
        "def mul_matrix(X, Y):\n",
        "    # mul_matrix Z[i][j] += X[i][k] * Y[k][j]\n",
        "    Z = [[sum(a * b for a, b in zip(X_row, Y_col)) for Y_col in zip(*Y)]\n",
        "            for X_row in X]\n",
        "\n",
        "    return Z\n",
        "\n",
        "\n",
        "def distribute_data():\n",
        "    # split matrix to p parts\n",
        "    def split_matrix(seq, p):\n",
        "        rows = []\n",
        "        n = int(len(seq) / p)\n",
        "        r = len(seq) % p\n",
        "        b, e = 0, n + min(1, r)\n",
        "        for i in range(p):\n",
        "            rows.append(seq[b:e])\n",
        "            r = max(0, r - 1)\n",
        "            b, e = e, e + n + min(1, r)\n",
        "\n",
        "        return rows\n",
        "\n",
        "    rows = split_matrix(mtrx_A, workers)\n",
        "\n",
        "    pid = 1\n",
        "    for row in rows:\n",
        "        # send p part of splited matrix to slave processes\n",
        "        comm.send(row, dest=pid, tag=1)\n",
        "        comm.send(mtrx_B, dest=pid, tag=2)\n",
        "        pid = pid + 1\n",
        "\n",
        "\n",
        "def assemble_data():\n",
        "    global mtrx_C\n",
        "\n",
        "    pid = 1\n",
        "    for n in range(workers):\n",
        "        # recieve p part of splited matrix from slave processes\n",
        "        row = comm.recv(source=pid, tag=pid)\n",
        "        # and assemble it to mtrx_C\n",
        "        mtrx_C = mtrx_C + row\n",
        "        pid = pid + 1\n",
        "\n",
        "\n",
        "def master_process():\n",
        "    # distribute matrix data to slaves\n",
        "    distribute_data()\n",
        "    # assemble salves returning values and generate final matrix\n",
        "    assemble_data()\n",
        "\n",
        "\n",
        "def slave_process():\n",
        "    # receive data from master node\n",
        "    x = comm.recv(source=0, tag=1)\n",
        "    y = comm.recv(source=0, tag=2)\n",
        "\n",
        "    # multiply the received matrix\n",
        "    z = mul_matrix(x, y)\n",
        "    # send the result back to master\n",
        "    comm.send(z, dest=0, tag=rank)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if rank == 0:\n",
        "        # start time\n",
        "        t1 = time.time()\n",
        "\n",
        "        master_process()\n",
        "\n",
        "        # end time\n",
        "        t2 = time.time()\n",
        "\n",
        "        # print(mtrx_A)\n",
        "        # print(mtrx_B)\n",
        "        # print(np.array(mtrx_C))\n",
        "        print(f'Time : {t2 - t1} (s)')\n",
        "    else:\n",
        "        slave_process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVtJYNtYW6mI"
      },
      "outputs": [],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 100\n",
        "! mpiexec --allow-run-as-root -np 5 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUjiiBsjZkc3"
      },
      "outputs": [],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 100\n",
        "! mpiexec --allow-run-as-root -np 9 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxDiKooNZkw-",
        "outputId": "bcfd8b36-e2e9-4903-d5a1-6d50d66a15cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[warn] Epoll ADD(4) on fd 29 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 71 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 74 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 83 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 84 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 86 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 88 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 91 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[warn] Epoll ADD(4) on fd 94 failed.  Old events were 0; read change was 0 (none); write change was 1 (add): Bad file descriptor\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 77 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],0] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 80 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],1] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 82 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],3] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 85 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],9] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 87 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],12] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 89 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],14] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 93 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],16] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 95 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],7] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 96 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],11] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 97 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],5] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 99 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],8] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 103 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],13] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 104 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],6] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 105 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],10] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] usock_peer_send_blocking: send() to socket 106 failed: Broken pipe (32)\n",
            "[9f18dedbd3a6:00575] [[53896,0],0] ORTE_ERROR_LOG: Unreachable in file oob_usock_connection.c at line 316\n",
            "[9f18dedbd3a6:00575] [[53896,0],0]-[[53896,1],15] usock_peer_accept: usock_peer_send_connect_ack failed\n",
            "[9f18dedbd3a6:00575] mpiexec: SIGPIPE detected on fd 13 - aborting\n",
            "mpiexec: abort is already in progress...hit ctrl-c again to forcibly terminate\n",
            "\n",
            "[9f18dedbd3a6:00575] mpiexec: SIGPIPE detected on fd 13 - aborting\n"
          ]
        }
      ],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 100\n",
        "! mpiexec --allow-run-as-root -np 17 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGRLDApBZ7cc"
      },
      "outputs": [],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 1000\n",
        "! mpiexec --allow-run-as-root -np 5 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AvOQd7WZ7ss"
      },
      "outputs": [],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 1000\n",
        "! mpiexec --allow-run-as-root -np 9 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoGP2lfAZ8E0"
      },
      "outputs": [],
      "source": [
        "# process include master_process 5, 9, 17 processes\n",
        "# N = 1000\n",
        "! mpiexec --allow-run-as-root -np 17 python mpi-mul.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBLtus4lOd9"
      },
      "source": [
        "# FILE : mpi-mul2.py\n",
        "\n",
        "Cannon's algorithm แต่คำตอบมันผิดแล้วมัน run นานมากผมไม่รู้จะทำยังไงแล้วครับ\n",
        "\n",
        "ตัวแปร\n",
        "\n",
        "**Line 11 :** workers คือ slave processes = comm.Get_size() - 1\n",
        "\n",
        "**Line 14 :** N คือขนาดของ array NxN numpy array\n",
        "\n",
        "**Line 17 :** mtrx_A คือ first numpy array value between 0 - 9 size NxN\n",
        "\n",
        "**Line 18 :** mtrx_B คือ second numpy array value between 0 - 9 size NxN\n",
        "\n",
        "**Line 19 :** mtrx_C คือ result numpy array\n",
        "\n",
        "**Line 22 :** mul_matrix function คือ matrix multiplier function ทำ *Z[i][j] += X[i][j] x Y[i][j]* ในทุก slave process\n",
        "\n",
        "**Line 30 :** distribute_data function คือแยก data ของ matrix จาก master process เป็นจำนวนเท่า square root ของ workers และยัดเข้าไปใน slave process แต่ละตัว โดยใช้ comm.send()\n",
        "\n",
        "**Line 54 :** assemble_data function คือรวม data ของ matrix ที่ผ่านการคูณมาแล้วใน slave processes มาใส่ใน mtrx_C โดยใช้ comm.recv ใน master process\n",
        "\n",
        "**Line 60 :** slave process roll ให้ matrix ที่ได้มา shift left matrix A แถวที่ i ไป i ช่อง shift up matrix B หลักที่ i ไป i ช่อง และค่อยทำการคูณ matrix และหลังจากนั้น shift left matrix A ทุกแถวไป 1 ช่อง และshift up matrix B ทุกหลักไป 1 ช่อง และวนไปเรื่อยๆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kawo0oCwCW3Y",
        "outputId": "6bfe24e1-8843-4668-c22a-affdfab425fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mpi-mul2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi-mul2.py\n",
        "from mpi4py import MPI\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "workers = comm.Get_size() - 1\n",
        "\n",
        "N = 10\n",
        "\n",
        "mtrx_A = np.random.randint(10,size=(N,N))\n",
        "mtrx_B = np.random.randint(10,size=(N,N))\n",
        "mtrx_C = np.zeros((N,N))\n",
        "\n",
        "def mul_matrix(X, Y,i,j):\n",
        "    Z = X[i][j] * Y[i][j]\n",
        "    return Z\n",
        "\n",
        "\n",
        "def distibute_data():\n",
        "    def split_matrix(seq, p):\n",
        "        rows = []\n",
        "        n = int(len(seq) / math.sqrt(p))\n",
        "        r = int(len(seq) % math.sqrt(p))\n",
        "        b, e = 0, n + min(1, r)\n",
        "        for i in range(int(math.sqrt(p))):\n",
        "            rows.append(seq[b:e])\n",
        "            r = max(0, r - 1)\n",
        "            b, e = e, e + n + min(1, r)\n",
        "\n",
        "        return rows\n",
        "\n",
        "    rows = split_matrix(mtrx_A, workers)\n",
        "\n",
        "    pid = 1\n",
        "    for row in rows:\n",
        "        comm.send(row, dest=pid, tag=1)\n",
        "        comm.send(mtrx_B, dest=pid, tag=2)\n",
        "        pid = pid + 1\n",
        "\n",
        "\n",
        "def assemble_data():\n",
        "    global mtrx_C\n",
        "\n",
        "    pid = 1\n",
        "    for n in range(int(math.sqrt(workers))):\n",
        "        row = comm.recv(source=pid, tag=pid)\n",
        "        mtrx_C = mtrx_C + row\n",
        "        pid = pid + 1\n",
        "\n",
        "\n",
        "def master_process():\n",
        "    distibute_data()\n",
        "    assemble_data()\n",
        "\n",
        "\n",
        "def slave_process():\n",
        "    # receive data from master node\n",
        "    x = comm.recv(source=0, tag=1)\n",
        "    y = comm.recv(source=0, tag=2)\n",
        "    z = np.zeros((N,N))\n",
        "\n",
        "    x2 = [np.roll(np.array(i), -1) for i in x]\n",
        "    y2 =  np.array(y)\n",
        "    for i in range(len(y2)):\n",
        "      y2[:,i] = np.roll(y2[:,i], -i)\n",
        "    # multiply the received matrix and send the result back to master\n",
        "\n",
        "    for i in range(len(x2)):\n",
        "      for j in range(len(y2)):\n",
        "        z[i][j] = mul_matrix(x2, y2,i,j)\n",
        "        np.roll(x2,-1,axis=0)\n",
        "        np.roll(y2,-1,axis=1)\n",
        "\n",
        "    comm.send(z, dest=0, tag=rank)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if rank == 0:\n",
        "\n",
        "        # start time\n",
        "        t1 = time.time()\n",
        "\n",
        "        master_process()\n",
        "\n",
        "        # end time\n",
        "        t2 = time.time()\n",
        "\n",
        "        print(mtrx_A)\n",
        "        print(mtrx_B)\n",
        "        print(mtrx_C)\n",
        "        print('Time taken in seconds', t2 - t1)\n",
        "    else:\n",
        "        slave_process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsBWDDHeIZP9",
        "outputId": "082bc45c-06f7-4a4f-feb9-69b7f301ee25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8 7 4 8 1 3 6 6 4 8]\n",
            " [3 1 2 0 3 2 1 4 4 2]\n",
            " [7 2 1 8 2 3 1 0 6 1]\n",
            " [5 5 5 1 1 3 1 7 0 9]\n",
            " [4 3 8 6 0 1 4 0 4 7]\n",
            " [5 6 0 1 8 8 2 5 7 7]\n",
            " [3 7 4 7 2 0 9 2 0 4]\n",
            " [1 9 3 4 2 3 3 7 1 6]\n",
            " [8 4 0 0 4 2 5 8 4 9]\n",
            " [8 9 8 2 9 8 4 4 6 8]]\n",
            "[[4 1 1 1 9 2 2 1 4 2]\n",
            " [6 3 7 1 4 8 9 8 2 0]\n",
            " [9 1 2 7 7 7 6 6 0 6]\n",
            " [2 4 9 4 7 4 1 7 9 7]\n",
            " [4 6 6 1 8 1 4 8 0 2]\n",
            " [2 1 5 9 3 0 4 9 5 0]\n",
            " [9 9 8 3 8 5 1 7 8 8]\n",
            " [7 1 8 3 6 8 9 5 7 9]\n",
            " [1 1 5 4 3 8 0 0 2 8]\n",
            " [0 7 7 5 1 4 4 1 7 4]]\n",
            "[[28. 12. 16.  4. 24.  0.  6. 20. 16. 32.]\n",
            " [ 6.  2.  0.  3.  6.  5. 36.  0. 14.  6.]\n",
            " [18.  4. 48. 18. 24.  8.  0.  6.  4.  0.]\n",
            " [10. 30.  5.  3. 18.  8. 28.  0. 18. 30.]\n",
            " [12.  8. 48.  0.  3. 16.  0. 32.  0. 28.]\n",
            " [12.  0.  8. 32.  8.  4. 45. 42. 63. 10.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "Time taken in seconds 0.472139835357666\n"
          ]
        }
      ],
      "source": [
        "! mpiexec --allow-run-as-root -np 4 python mpi-mul2.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}